{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367b1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a819c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size =64\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12694145",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"./cehckpoint\"\n",
    "log_dir   = \"./log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c191b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb38ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels=10, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 10, out_channels=20, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "        self.drop2 = nn.Dropout2d(p=0.5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 320,  out_features=50, bias=True)\n",
    "        self.relu1_fc1 = nn.ReLU()\n",
    "        self.drop1_fc1 = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10, bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x.view(-1, 320)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1_fc1(x)\n",
    "        x = self.drop1_fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b6a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.mkdir(ckpt_dir)\n",
    "        \n",
    "        torch.save({\"net\":net.state_dict(), \"optim\":optim.state_dict()}, f\"./{ckpt_dir}/epoch{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(ckpt_dir, net, optim):\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort()\n",
    "    \n",
    "    dict_model = torch.load(f\"./{ckpt_dir}/{ckpt_lst[-1]}\")\n",
    "    \n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    \n",
    "    return net, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c74946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "dataset = datasets.MNIST(download=True, root=\"./\", train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3f4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553c50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = len(loader.dataset)\n",
    "num_batch = int(np.ceil(num_data/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd679ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "params = net.parameters()\n",
    "\n",
    "fn_loss  = nn.CrossEntropyLoss().to(device)\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "\n",
    "optim = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "net, optim = load(ckpt_dir=ckpt_dir, net=net, optim=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "172fd013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | BATCH 0001 / 0157| LOSS 0.0223 ACC 1.0000\n",
      "Test | BATCH 0002 / 0157| LOSS 0.0488 ACC 0.9844\n",
      "Test | BATCH 0003 / 0157| LOSS 0.0439 ACC 0.9896\n",
      "Test | BATCH 0004 / 0157| LOSS 0.0555 ACC 0.9844\n",
      "Test | BATCH 0005 / 0157| LOSS 0.0756 ACC 0.9750\n",
      "Test | BATCH 0006 / 0157| LOSS 0.0750 ACC 0.9740\n",
      "Test | BATCH 0007 / 0157| LOSS 0.0739 ACC 0.9754\n",
      "Test | BATCH 0008 / 0157| LOSS 0.0942 ACC 0.9688\n",
      "Test | BATCH 0009 / 0157| LOSS 0.0899 ACC 0.9722\n",
      "Test | BATCH 0010 / 0157| LOSS 0.0938 ACC 0.9703\n",
      "Test | BATCH 0011 / 0157| LOSS 0.0947 ACC 0.9688\n",
      "Test | BATCH 0012 / 0157| LOSS 0.0976 ACC 0.9661\n",
      "Test | BATCH 0013 / 0157| LOSS 0.0926 ACC 0.9688\n",
      "Test | BATCH 0014 / 0157| LOSS 0.0907 ACC 0.9699\n",
      "Test | BATCH 0015 / 0157| LOSS 0.1025 ACC 0.9646\n",
      "Test | BATCH 0016 / 0157| LOSS 0.1030 ACC 0.9648\n",
      "Test | BATCH 0017 / 0157| LOSS 0.1020 ACC 0.9651\n",
      "Test | BATCH 0018 / 0157| LOSS 0.1058 ACC 0.9644\n",
      "Test | BATCH 0019 / 0157| LOSS 0.1056 ACC 0.9646\n",
      "Test | BATCH 0020 / 0157| LOSS 0.1160 ACC 0.9633\n",
      "Test | BATCH 0021 / 0157| LOSS 0.1248 ACC 0.9613\n",
      "Test | BATCH 0022 / 0157| LOSS 0.1212 ACC 0.9624\n",
      "Test | BATCH 0023 / 0157| LOSS 0.1201 ACC 0.9633\n",
      "Test | BATCH 0024 / 0157| LOSS 0.1228 ACC 0.9622\n",
      "Test | BATCH 0025 / 0157| LOSS 0.1237 ACC 0.9625\n",
      "Test | BATCH 0026 / 0157| LOSS 0.1235 ACC 0.9627\n",
      "Test | BATCH 0027 / 0157| LOSS 0.1289 ACC 0.9612\n",
      "Test | BATCH 0028 / 0157| LOSS 0.1303 ACC 0.9615\n",
      "Test | BATCH 0029 / 0157| LOSS 0.1277 ACC 0.9623\n",
      "Test | BATCH 0030 / 0157| LOSS 0.1286 ACC 0.9625\n",
      "Test | BATCH 0031 / 0157| LOSS 0.1267 ACC 0.9637\n",
      "Test | BATCH 0032 / 0157| LOSS 0.1286 ACC 0.9634\n",
      "Test | BATCH 0033 / 0157| LOSS 0.1285 ACC 0.9635\n",
      "Test | BATCH 0034 / 0157| LOSS 0.1289 ACC 0.9632\n",
      "Test | BATCH 0035 / 0157| LOSS 0.1304 ACC 0.9625\n",
      "Test | BATCH 0036 / 0157| LOSS 0.1324 ACC 0.9618\n",
      "Test | BATCH 0037 / 0157| LOSS 0.1308 ACC 0.9624\n",
      "Test | BATCH 0038 / 0157| LOSS 0.1339 ACC 0.9618\n",
      "Test | BATCH 0039 / 0157| LOSS 0.1315 ACC 0.9623\n",
      "Test | BATCH 0040 / 0157| LOSS 0.1287 ACC 0.9633\n",
      "Test | BATCH 0041 / 0157| LOSS 0.1286 ACC 0.9630\n",
      "Test | BATCH 0042 / 0157| LOSS 0.1285 ACC 0.9632\n",
      "Test | BATCH 0043 / 0157| LOSS 0.1266 ACC 0.9640\n",
      "Test | BATCH 0044 / 0157| LOSS 0.1260 ACC 0.9641\n",
      "Test | BATCH 0045 / 0157| LOSS 0.1237 ACC 0.9649\n",
      "Test | BATCH 0046 / 0157| LOSS 0.1246 ACC 0.9647\n",
      "Test | BATCH 0047 / 0157| LOSS 0.1265 ACC 0.9631\n",
      "Test | BATCH 0048 / 0157| LOSS 0.1251 ACC 0.9635\n",
      "Test | BATCH 0049 / 0157| LOSS 0.1249 ACC 0.9633\n",
      "Test | BATCH 0050 / 0157| LOSS 0.1232 ACC 0.9641\n",
      "Test | BATCH 0051 / 0157| LOSS 0.1229 ACC 0.9638\n",
      "Test | BATCH 0052 / 0157| LOSS 0.1213 ACC 0.9642\n",
      "Test | BATCH 0053 / 0157| LOSS 0.1230 ACC 0.9631\n",
      "Test | BATCH 0054 / 0157| LOSS 0.1213 ACC 0.9638\n",
      "Test | BATCH 0055 / 0157| LOSS 0.1214 ACC 0.9636\n",
      "Test | BATCH 0056 / 0157| LOSS 0.1234 ACC 0.9637\n",
      "Test | BATCH 0057 / 0157| LOSS 0.1234 ACC 0.9641\n",
      "Test | BATCH 0058 / 0157| LOSS 0.1220 ACC 0.9644\n",
      "Test | BATCH 0059 / 0157| LOSS 0.1248 ACC 0.9640\n",
      "Test | BATCH 0060 / 0157| LOSS 0.1279 ACC 0.9625\n",
      "Test | BATCH 0061 / 0157| LOSS 0.1284 ACC 0.9623\n",
      "Test | BATCH 0062 / 0157| LOSS 0.1298 ACC 0.9619\n",
      "Test | BATCH 0063 / 0157| LOSS 0.1298 ACC 0.9618\n",
      "Test | BATCH 0064 / 0157| LOSS 0.1307 ACC 0.9617\n",
      "Test | BATCH 0065 / 0157| LOSS 0.1294 ACC 0.9623\n",
      "Test | BATCH 0066 / 0157| LOSS 0.1300 ACC 0.9616\n",
      "Test | BATCH 0067 / 0157| LOSS 0.1311 ACC 0.9613\n",
      "Test | BATCH 0068 / 0157| LOSS 0.1302 ACC 0.9614\n",
      "Test | BATCH 0069 / 0157| LOSS 0.1295 ACC 0.9617\n",
      "Test | BATCH 0070 / 0157| LOSS 0.1284 ACC 0.9621\n",
      "Test | BATCH 0071 / 0157| LOSS 0.1285 ACC 0.9619\n",
      "Test | BATCH 0072 / 0157| LOSS 0.1278 ACC 0.9620\n",
      "Test | BATCH 0073 / 0157| LOSS 0.1278 ACC 0.9621\n",
      "Test | BATCH 0074 / 0157| LOSS 0.1270 ACC 0.9622\n",
      "Test | BATCH 0075 / 0157| LOSS 0.1267 ACC 0.9619\n",
      "Test | BATCH 0076 / 0157| LOSS 0.1271 ACC 0.9620\n",
      "Test | BATCH 0077 / 0157| LOSS 0.1281 ACC 0.9616\n",
      "Test | BATCH 0078 / 0157| LOSS 0.1281 ACC 0.9617\n",
      "Test | BATCH 0079 / 0157| LOSS 0.1266 ACC 0.9622\n",
      "Test | BATCH 0080 / 0157| LOSS 0.1256 ACC 0.9625\n",
      "Test | BATCH 0081 / 0157| LOSS 0.1245 ACC 0.9628\n",
      "Test | BATCH 0082 / 0157| LOSS 0.1233 ACC 0.9632\n",
      "Test | BATCH 0083 / 0157| LOSS 0.1222 ACC 0.9637\n",
      "Test | BATCH 0084 / 0157| LOSS 0.1208 ACC 0.9641\n",
      "Test | BATCH 0085 / 0157| LOSS 0.1194 ACC 0.9645\n",
      "Test | BATCH 0086 / 0157| LOSS 0.1181 ACC 0.9649\n",
      "Test | BATCH 0087 / 0157| LOSS 0.1168 ACC 0.9653\n",
      "Test | BATCH 0088 / 0157| LOSS 0.1159 ACC 0.9656\n",
      "Test | BATCH 0089 / 0157| LOSS 0.1150 ACC 0.9658\n",
      "Test | BATCH 0090 / 0157| LOSS 0.1148 ACC 0.9660\n",
      "Test | BATCH 0091 / 0157| LOSS 0.1136 ACC 0.9663\n",
      "Test | BATCH 0092 / 0157| LOSS 0.1141 ACC 0.9659\n",
      "Test | BATCH 0093 / 0157| LOSS 0.1142 ACC 0.9657\n",
      "Test | BATCH 0094 / 0157| LOSS 0.1144 ACC 0.9656\n",
      "Test | BATCH 0095 / 0157| LOSS 0.1146 ACC 0.9650\n",
      "Test | BATCH 0096 / 0157| LOSS 0.1151 ACC 0.9650\n",
      "Test | BATCH 0097 / 0157| LOSS 0.1154 ACC 0.9649\n",
      "Test | BATCH 0098 / 0157| LOSS 0.1143 ACC 0.9652\n",
      "Test | BATCH 0099 / 0157| LOSS 0.1131 ACC 0.9656\n",
      "Test | BATCH 0100 / 0157| LOSS 0.1121 ACC 0.9659\n",
      "Test | BATCH 0101 / 0157| LOSS 0.1111 ACC 0.9663\n",
      "Test | BATCH 0102 / 0157| LOSS 0.1111 ACC 0.9665\n",
      "Test | BATCH 0103 / 0157| LOSS 0.1116 ACC 0.9662\n",
      "Test | BATCH 0104 / 0157| LOSS 0.1134 ACC 0.9657\n",
      "Test | BATCH 0105 / 0157| LOSS 0.1125 ACC 0.9661\n",
      "Test | BATCH 0106 / 0157| LOSS 0.1121 ACC 0.9662\n",
      "Test | BATCH 0107 / 0157| LOSS 0.1113 ACC 0.9664\n",
      "Test | BATCH 0108 / 0157| LOSS 0.1106 ACC 0.9666\n",
      "Test | BATCH 0109 / 0157| LOSS 0.1096 ACC 0.9669\n",
      "Test | BATCH 0110 / 0157| LOSS 0.1087 ACC 0.9672\n",
      "Test | BATCH 0111 / 0157| LOSS 0.1078 ACC 0.9675\n",
      "Test | BATCH 0112 / 0157| LOSS 0.1070 ACC 0.9676\n",
      "Test | BATCH 0113 / 0157| LOSS 0.1062 ACC 0.9679\n",
      "Test | BATCH 0114 / 0157| LOSS 0.1055 ACC 0.9682\n",
      "Test | BATCH 0115 / 0157| LOSS 0.1046 ACC 0.9685\n",
      "Test | BATCH 0116 / 0157| LOSS 0.1038 ACC 0.9688\n",
      "Test | BATCH 0117 / 0157| LOSS 0.1038 ACC 0.9688\n",
      "Test | BATCH 0118 / 0157| LOSS 0.1033 ACC 0.9689\n",
      "Test | BATCH 0119 / 0157| LOSS 0.1026 ACC 0.9691\n",
      "Test | BATCH 0120 / 0157| LOSS 0.1018 ACC 0.9694\n",
      "Test | BATCH 0121 / 0157| LOSS 0.1013 ACC 0.9695\n",
      "Test | BATCH 0122 / 0157| LOSS 0.1006 ACC 0.9696\n",
      "Test | BATCH 0123 / 0157| LOSS 0.1005 ACC 0.9698\n",
      "Test | BATCH 0124 / 0157| LOSS 0.1006 ACC 0.9696\n",
      "Test | BATCH 0125 / 0157| LOSS 0.0999 ACC 0.9699\n",
      "Test | BATCH 0126 / 0157| LOSS 0.0991 ACC 0.9701\n",
      "Test | BATCH 0127 / 0157| LOSS 0.0990 ACC 0.9702\n",
      "Test | BATCH 0128 / 0157| LOSS 0.0986 ACC 0.9703\n",
      "Test | BATCH 0129 / 0157| LOSS 0.0980 ACC 0.9706\n",
      "Test | BATCH 0130 / 0157| LOSS 0.0978 ACC 0.9706\n",
      "Test | BATCH 0131 / 0157| LOSS 0.0972 ACC 0.9708\n",
      "Test | BATCH 0132 / 0157| LOSS 0.0968 ACC 0.9709\n",
      "Test | BATCH 0133 / 0157| LOSS 0.0963 ACC 0.9709\n",
      "Test | BATCH 0134 / 0157| LOSS 0.0957 ACC 0.9711\n",
      "Test | BATCH 0135 / 0157| LOSS 0.0950 ACC 0.9713\n",
      "Test | BATCH 0136 / 0157| LOSS 0.0944 ACC 0.9715\n",
      "Test | BATCH 0137 / 0157| LOSS 0.0937 ACC 0.9717\n",
      "Test | BATCH 0138 / 0157| LOSS 0.0930 ACC 0.9719\n",
      "Test | BATCH 0139 / 0157| LOSS 0.0924 ACC 0.9721\n",
      "Test | BATCH 0140 / 0157| LOSS 0.0917 ACC 0.9723\n",
      "Test | BATCH 0141 / 0157| LOSS 0.0927 ACC 0.9722\n",
      "Test | BATCH 0142 / 0157| LOSS 0.0930 ACC 0.9722\n",
      "Test | BATCH 0143 / 0157| LOSS 0.0924 ACC 0.9724\n",
      "Test | BATCH 0144 / 0157| LOSS 0.0918 ACC 0.9725\n",
      "Test | BATCH 0145 / 0157| LOSS 0.0913 ACC 0.9727\n",
      "Test | BATCH 0146 / 0157| LOSS 0.0908 ACC 0.9728\n",
      "Test | BATCH 0147 / 0157| LOSS 0.0902 ACC 0.9730\n",
      "Test | BATCH 0148 / 0157| LOSS 0.0897 ACC 0.9732\n",
      "Test | BATCH 0149 / 0157| LOSS 0.0894 ACC 0.9733\n",
      "Test | BATCH 0150 / 0157| LOSS 0.0890 ACC 0.9733\n",
      "Test | BATCH 0151 / 0157| LOSS 0.0893 ACC 0.9733\n",
      "Test | BATCH 0152 / 0157| LOSS 0.0893 ACC 0.9732\n",
      "Test | BATCH 0153 / 0157| LOSS 0.0906 ACC 0.9729\n",
      "Test | BATCH 0154 / 0157| LOSS 0.0904 ACC 0.9730\n",
      "Test | BATCH 0155 / 0157| LOSS 0.0909 ACC 0.9727\n",
      "Test | BATCH 0156 / 0157| LOSS 0.0914 ACC 0.9726\n",
      "Test | BATCH 0157 / 0157| LOSS 0.0908 ACC 0.9727\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    \n",
    "    loss_arr = []\n",
    "    acc_arr  = []\n",
    "    \n",
    "    for batch, (inputs,label) in enumerate(loader, 1):\n",
    "        inputs = inputs.to(device)\n",
    "        label  = label.to(device)\n",
    "        output = net(inputs)\n",
    "        pred   = fn_pred(output)\n",
    "\n",
    "        loss= fn_loss(output, label)\n",
    "        acc = fn_acc(pred, label)\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        loss_arr += [loss.item()]\n",
    "        acc_arr  += [acc.item()]\n",
    "        \n",
    "        print(f\"Test | BATCH {batch:04d} / {num_batch:04d}| LOSS {np.mean(loss_arr):.4f} ACC {np.mean(acc_arr):.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
